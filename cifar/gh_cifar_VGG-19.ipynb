{"cells":[{"cell_type":"markdown","source":["# 라이브러리"],"metadata":{"id":"E5a__yWz4kv4"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from __future__ import print_function\n","from torch import nn, optim, cuda\n","from torch.utils import data\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","path = \"/content/drive/MyDrive/21_winter/CIFAR-10/cifar-10-batches-py\"\n","batch_size = 32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiwWQk-F4kUq","executionInfo":{"status":"ok","timestamp":1642746475475,"user_tz":-540,"elapsed":2474,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}},"outputId":"2cea6844-58ba-4073-84cb-71e14eba5283"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"RhqYe3OUcs-I"},"source":["# 데이터 불러오기"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"pXcSC373cs-K","executionInfo":{"status":"ok","timestamp":1642746475887,"user_tz":-540,"elapsed":419,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","data_list = [\"/data_batch_\" + str(i) for i in range(2,6)]\n","train_data = unpickle(path + \"/data_batch_1\")\n","test_data = unpickle(path + \"/test_batch\")\n","\n","train_data_img = train_data[b'data']\n","train_data_labels = train_data[b'labels']\n","for i in data_list:\n","  train_data = unpickle(path + i)\n","  train_data_img = np.concatenate((train_data_img,train_data[b'data']))\n","  train_data_labels += train_data[b'labels']\n"]},{"cell_type":"markdown","metadata":{"id":"SQpFa2qPcs-M"},"source":["# 데이터 준비"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"68fOgs4Pcs-M","executionInfo":{"status":"ok","timestamp":1642746476177,"user_tz":-540,"elapsed":292,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["class GH_Dataset(data.Dataset): \n","    def __init__(self,X,Y):\n","        self.x_data = torch.from_numpy(X).type(dtype=torch.float32).resize_((10000,3,32,32))\n","        self.y_data = torch.tensor(Y).resize_(10000,1)\n","\n","    def __len__(self): \n","        return len(self.x_data)\n","    \n","    def __getitem__(self, idx): \n","        x = self.x_data[idx]\n","        y = self.y_data[idx]\n","        return x, y\n","\n","train_dataset = GH_Dataset(train_data_img,train_data_labels)\n","train_loader = data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n","\n","test_dataset = GH_Dataset(test_data[b'data'],test_data[b'labels'])\n","test_loader = data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"dgq0mvvVcs-N"},"source":["# 모델"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"rtRN2gNFcs-N","executionInfo":{"status":"ok","timestamp":1642746476442,"user_tz":-540,"elapsed":266,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["class GH(nn.Module):\n","    def __init__(self):\n","        super(GH,self).__init__()\n","        self.l1 = nn.Conv2d(3 ,64,3, padding = 1)\n","        self.l2 = nn.Conv2d(64,64,3, padding = 1)\n","\n","        self.l3 = nn.Conv2d(64,128,3, padding = 1)\n","        self.l4 = nn.Conv2d(128,128,3, padding = 1)\n","\n","        self.l5 = nn.Conv2d(128,256,3, padding = 1)\n","        self.l6 = nn.Conv2d(256,256,3, padding = 1)\n","        \n","        self.l7 = nn.Conv2d(256,512,3, padding = 1)\n","        self.l8 = nn.Conv2d(512,512,3, padding = 1)\n","        self.l9 = nn.Conv2d(512,512,3, padding = 1)\n","\n","        self.l10 = nn.Linear(2048,2048)   \n","        self.l11 = nn.Linear(2048,2048)\n","        self.l12 = nn.Linear(2048,10)\n","    \n","    def forward(self, x):      #(n,3,32,32)\n","        x = F.relu(self.l1(x)) #(n,64,32,32)\n","        x = F.relu(self.l2(x)) #(n,64,32,32)\n","        x = F.max_pool2d(x,2)  #(n,64,16,16)\n","\n","        x = F.relu(self.l3(x)) #(n,128,16,16)\n","        x = F.relu(self.l4(x)) #(n,128,16,16)\n","        x = F.max_pool2d(x,2)  #(n,128, 8, 8)\n","\n","        x = F.relu(self.l5(x)) #(n,256, 8, 8)\n","        x = F.relu(self.l6(x)) #(n,256, 8, 8)\n","        x = F.max_pool2d(x,2)  #(n,256, 4, 4)\n","\n","        x = F.relu(self.l7(x)) #(n,512, 4, 4)\n","        x = F.relu(self.l8(x)) #(n,512, 4, 4)\n","        x = F.relu(self.l8(x)) #(n,512, 4, 4)\n","        x = F.max_pool2d(x,2)  #(n,512, 2, 2)\n","\n","        x = x.view(-1,2048)    #(n,2048)\n","        x = F.relu(self.l10(x)) #(n,2048)\n","        x = F.relu(self.l11(x)) #(n,2048)\n","        x = F.relu(self.l12(x)) #(n,10) \n","        return x               #(n,10)\n","    \n","model = GH()\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.00005)\n","\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, torch.squeeze(target))\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx %100000 == 0:\n","            print('==================\\nTrain Epoch : {} | Batch Status : {}/{} ({:.0f}%) | Loss : {:.6f}'.format(\n","                epoch, batch_idx*len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        # sum up batch loss\n","        test_loss += criterion(output, torch.squeeze(target)).item()\n","        # get the index of the max\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","    test_loss /= len(test_loader.dataset)\n","    print(f'Test set: Average loss : {test_loss:.4f}, Accuracy : {correct}/{len(test_loader.dataset)}'\n","          f'({100. * correct / len(test_loader.dataset):.0f}%)')"]},{"cell_type":"markdown","metadata":{"id":"WlEixH6mcs-O"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8DLELNAcs-O","executionInfo":{"status":"ok","timestamp":1642746549428,"user_tz":-540,"elapsed":72988,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}},"outputId":"67dbd577-e91e-41e0-9593-cca04041fe86"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================\n","Train Epoch : 1 | Batch Status : 0/10000 (0%) | Loss : 2.304150\n","Training time: 0m 6s\n","Test set: Average loss : 0.0707, Accuracy : 1610/10000(16%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 2 | Batch Status : 0/10000 (0%) | Loss : 2.298559\n","Training time: 0m 6s\n","Test set: Average loss : 0.0707, Accuracy : 1609/10000(16%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 3 | Batch Status : 0/10000 (0%) | Loss : 2.265885\n","Training time: 0m 6s\n","Test set: Average loss : 0.0677, Accuracy : 2367/10000(24%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 4 | Batch Status : 0/10000 (0%) | Loss : 2.229309\n","Training time: 0m 6s\n","Test set: Average loss : 0.0664, Accuracy : 2618/10000(26%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 5 | Batch Status : 0/10000 (0%) | Loss : 2.233996\n","Training time: 0m 6s\n","Test set: Average loss : 0.0657, Accuracy : 2678/10000(27%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 6 | Batch Status : 0/10000 (0%) | Loss : 2.030678\n","Training time: 0m 6s\n","Test set: Average loss : 0.0654, Accuracy : 2735/10000(27%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 7 | Batch Status : 0/10000 (0%) | Loss : 2.080415\n","Training time: 0m 6s\n","Test set: Average loss : 0.0657, Accuracy : 2521/10000(25%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 8 | Batch Status : 0/10000 (0%) | Loss : 1.939559\n","Training time: 0m 6s\n","Test set: Average loss : 0.0665, Accuracy : 2638/10000(26%)\n","Tesing time: 0m 8s\n","==================\n","Train Epoch : 9 | Batch Status : 0/10000 (0%) | Loss : 2.088159\n","Training time: 0m 6s\n","Test set: Average loss : 0.0679, Accuracy : 2650/10000(26%)\n","Tesing time: 0m 8s\n","Total time : 0m  8s \n","Model was trained on cuda!\n"]}],"source":["if __name__ == '__main__':\n","    since = time.time()\n","    for epoch in range(1, 10):\n","        epoch_start = time.time()\n","        train(epoch)\n","        m, s = divmod(time.time() - epoch_start, 60)\n","        print(f'Training time: {m:.0f}m {s:.0f}s')\n","        \n","        test()\n","        m, s = divmod(time.time() - epoch_start, 60)\n","        print(f'Tesing time: {m:.0f}m {s:.0f}s')\n","        \n","    m, s = divmod(time.time() - epoch_start, 60)\n","    print(f'Total time : {m:.0f}m {s: .0f}s \\nModel was trained on {device}!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAlpNx5kcs-P","executionInfo":{"status":"aborted","timestamp":1642746289022,"user_tz":-540,"elapsed":4,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["\"\"\"\n","이미지 데이터의 크기가 32*32 사이즈이므로 pool을 여러번 적용하게 되면서 데이터의 손실이 일어나 예측이 낮아진것이라 생각됨\n","\"\"\""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Untitled.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}