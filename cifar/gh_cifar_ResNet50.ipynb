{"cells":[{"cell_type":"markdown","source":["# 라이브러리"],"metadata":{"id":"E5a__yWz4kv4"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from __future__ import print_function\n","from torch import nn, optim, cuda\n","from torch.utils import data\n","from torchvision import datasets, transforms\n","import torch.nn.functional as F\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","path = \"/content/drive/MyDrive/21_winter/CIFAR-10/cifar-10-batches-py\"\n","batch_size = 32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiwWQk-F4kUq","executionInfo":{"status":"ok","timestamp":1642747365485,"user_tz":-540,"elapsed":2276,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}},"outputId":"8544ed82-4ddd-46fe-eedd-b025ffd37a26"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"RhqYe3OUcs-I"},"source":["# 데이터 불러오기"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pXcSC373cs-K","executionInfo":{"status":"ok","timestamp":1642747365905,"user_tz":-540,"elapsed":426,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["def unpickle(file):\n","    import pickle\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    return dict\n","data_list = [\"/data_batch_\" + str(i) for i in range(2,6)]\n","train_data = unpickle(path + \"/data_batch_1\")\n","test_data = unpickle(path + \"/test_batch\")\n","\n","train_data_img = train_data[b'data']\n","train_data_labels = train_data[b'labels']\n","for i in data_list:\n","  train_data = unpickle(path + i)\n","  train_data_img = np.concatenate((train_data_img,train_data[b'data']))\n","  train_data_labels += train_data[b'labels']\n"]},{"cell_type":"markdown","metadata":{"id":"SQpFa2qPcs-M"},"source":["# 데이터 준비"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"68fOgs4Pcs-M","executionInfo":{"status":"ok","timestamp":1642747365905,"user_tz":-540,"elapsed":6,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}}},"outputs":[],"source":["class GH_Dataset(data.Dataset): \n","    def __init__(self,X,Y):\n","        self.x_data = torch.from_numpy(X).type(dtype=torch.float32).resize_((10000,3,32,32))\n","        self.y_data = torch.tensor(Y).resize_(10000,1)\n","\n","    def __len__(self): \n","        return len(self.x_data)\n","    \n","    def __getitem__(self, idx): \n","        x = self.x_data[idx]\n","        y = self.y_data[idx]\n","        return x, y\n","\n","train_dataset = GH_Dataset(train_data_img,train_data_labels)\n","train_loader = data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n","\n","test_dataset = GH_Dataset(test_data[b'data'],test_data[b'labels'])\n","test_loader = data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"dgq0mvvVcs-N"},"source":["# 모델"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"rtRN2gNFcs-N","executionInfo":{"status":"ok","timestamp":1642747966233,"user_tz":-540,"elapsed":647,"user":{"displayName":"허건혁/학생/수학","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13464339456284199823"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a3d36299-8261-47f3-b382-b0916daadc4d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}],"source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n","model.to(device)\n","\n","\"\"\"\n","config = {\n","    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n","    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n","    \"lr\": tune.loguniform(1e-4, 1e-1),\n","    \"batch_size\": tune.choice([2, 4, 8, 16])\n","}\n","\"\"\"\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, torch.squeeze(target))\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx %100000 == 0:\n","            print('==================\\nTrain Epoch : {} | Batch Status : {}/{} ({:.0f}%) | Loss : {:.6f}'.format(\n","                epoch, batch_idx*len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        # sum up batch loss\n","        test_loss += criterion(output, torch.squeeze(target)).item()\n","        # get the index of the max\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","    test_loss /= len(test_loader.dataset)\n","    print(f'Test set: Average loss : {test_loss:.4f}, Accuracy : {correct}/{len(test_loader.dataset)}'\n","          f'({100. * correct / len(test_loader.dataset):.0f}%)')"]},{"cell_type":"markdown","metadata":{"id":"WlEixH6mcs-O"},"source":["# 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8DLELNAcs-O","outputId":"82d91045-8c21-4836-9140-0f239fd81561"},"outputs":[{"output_type":"stream","name":"stdout","text":["==================\n","Train Epoch : 1 | Batch Status : 0/10000 (0%) | Loss : 12.167669\n","Training time: 0m 17s\n","Test set: Average loss : 0.0351, Accuracy : 6195/10000(62%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 2 | Batch Status : 0/10000 (0%) | Loss : 0.927308\n","Training time: 0m 16s\n","Test set: Average loss : 0.0288, Accuracy : 6858/10000(69%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 3 | Batch Status : 0/10000 (0%) | Loss : 0.737214\n","Training time: 0m 16s\n","Test set: Average loss : 0.0280, Accuracy : 7110/10000(71%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 4 | Batch Status : 0/10000 (0%) | Loss : 0.605924\n","Training time: 0m 16s\n","Test set: Average loss : 0.0275, Accuracy : 7248/10000(72%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 5 | Batch Status : 0/10000 (0%) | Loss : 0.414832\n","Training time: 0m 16s\n","Test set: Average loss : 0.0290, Accuracy : 7222/10000(72%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 6 | Batch Status : 0/10000 (0%) | Loss : 0.251160\n","Training time: 0m 16s\n","Test set: Average loss : 0.0278, Accuracy : 7393/10000(74%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 7 | Batch Status : 0/10000 (0%) | Loss : 0.053227\n","Training time: 0m 16s\n","Test set: Average loss : 0.0303, Accuracy : 7331/10000(73%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 8 | Batch Status : 0/10000 (0%) | Loss : 0.123471\n","Training time: 0m 16s\n","Test set: Average loss : 0.0308, Accuracy : 7289/10000(73%)\n","Tesing time: 0m 21s\n","==================\n","Train Epoch : 9 | Batch Status : 0/10000 (0%) | Loss : 0.034272\n"]}],"source":["if __name__ == '__main__':\n","    since = time.time()\n","    for epoch in range(1, 10):\n","        epoch_start = time.time()\n","        train(epoch)\n","        m, s = divmod(time.time() - epoch_start, 60)\n","        print(f'Training time: {m:.0f}m {s:.0f}s')\n","        \n","        test()\n","        m, s = divmod(time.time() - epoch_start, 60)\n","        print(f'Tesing time: {m:.0f}m {s:.0f}s')\n","        \n","    m, s = divmod(time.time() - epoch_start, 60)\n","    print(f'Total time : {m:.0f}m {s: .0f}s \\nModel was trained on {device}!')"]},{"cell_type":"code","source":[""],"metadata":{"id":"CIoIiyGhYjMJ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"Untitled.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}